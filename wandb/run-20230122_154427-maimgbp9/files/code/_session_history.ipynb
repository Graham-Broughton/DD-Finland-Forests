{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c9b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3a92cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchgeo.transforms import indices\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import dotenv\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning) # biomassters rasters are not georeferenced\n",
    "warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb58ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "os.chdir(os.environ['WORKING_DIR'])\n",
    "import src.utils.transforms as tf\n",
    "import src.utils.data_loader_v3 as dl\n",
    "from config import CFG, CFG2\n",
    "CFG = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ffddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d527719",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "if torch.backends.mps.is_available(): # Mac M1/M2\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "loader_device = torch.device('cpu')  # found that using cpu for data loading was faster than gpu (for my device)\n",
    "print(f'training device: {device}')\n",
    "print(f'loader_device: {loader_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c067c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map of tensor channels *after* transforms, not accounting for bands dropped by the DropBands transform\n",
    "# Useful for choosing which bands to keep \n",
    "band_map = CFG2.BAND_MAP\n",
    "month_map = CFG2.MONTH_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74555bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_to_keep = CFG.BANDS # via offline feature selection  \n",
    "\n",
    "transforms = nn.Sequential(\n",
    "    tf.ClampAGBM(vmin=0., vmax=500.),                # exclude AGBM outliers, 500 is good upper limit per AGBM histograms \n",
    "    indices.AppendNDVI(index_nir=6, index_red=2),    # NDVI, index 15\n",
    "    indices.AppendNormalizedDifferenceIndex(index_a=11, index_b=12), # (VV-VH)/(VV+VH), index 16\n",
    "    indices.AppendNDBI(index_swir=8, index_nir=6),   # Difference Built-up Index for development detection, index 17\n",
    "    indices.AppendNDRE(index_nir=6, index_vre1=3),   # Red Edge Vegetation Index for canopy detection, index 18\n",
    "    indices.AppendNDSI(index_green=1, index_swir=8), # Snow Index, index 19\n",
    "    indices.AppendNDWI(index_green=1, index_nir=6),  # Difference Water Index for water detection, index 20 \n",
    "    indices.AppendSWI(index_vre1=3, index_swir2=8),  # Standardized Water-Level Index for water detection, index 21\n",
    "    tf.AppendRatioAB(index_a=11, index_b=12),        # VV/VH Ascending, index 22\n",
    "    tf.AppendRatioAB(index_a=13, index_b=14),        # VV/VH Descending, index 23\n",
    "    tf.DropBands(loader_device, bands_to_keep)       # DROPS ALL BUT SPECIFIED bands_to_keep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79e3a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    train_metrics = []\n",
    "    example_ct = 0\n",
    "    \n",
    "    print('Training')\n",
    "    for ix, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        X = batch['image'].to(device)\n",
    "        y = batch['label'].to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_metrics.append(np.round(np.sqrt(loss.item()), 5))\n",
    "\n",
    "        example_cnt += ix * len(batch)\n",
    "        if ((ix + 1) % 25) == 0:\n",
    "            train_log(train_metrics[-1], example_cnt)\n",
    "            \n",
    "    return train_metrics\n",
    "\n",
    "\n",
    "def valid_loop(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss = 0\n",
    "    valid_metrics = {}\n",
    "    example_ct = 0\n",
    "    \n",
    "    print('Validation')\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=num_batches):\n",
    "            X = batch['image'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "    valid_loss /= num_batches\n",
    "    valid_rmse = np.round(np.sqrt(valid_loss), 5)\n",
    "    print(f\"Validation Error: \\n RMSE: {valid_rmse:>8f} \\n\")\n",
    "    wandb.log({\"test_accuracy\": valid_rmse})\n",
    "    return valid_rmse\n",
    "\n",
    "def train_log(loss, example_ct):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"loss\": loss}, step=example_ct)\n",
    "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ffa8532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, loss_module, optimizer, train_dataloader, val_dataloader, CFG):\n",
    "    save_file = f'UNET_resnet50_20band_batch{CFG.BATCH_SIZE}_AGBMLinear_AllTrain_{CFG.EPOCHS}epoch_{datetime.now()}.pt'\n",
    "    save_path = os.path.join(CFG.SAVED_MODELS, save_file)\n",
    "    wandb.watch(model, loss_module, log=\"all\", log_freq=10)\n",
    "    min_valid_metric = np.inf\n",
    "    train_metrics = []\n",
    "    valid_metrics = []\n",
    "\n",
    "    for ix in range(CFG.EPOCHS):\n",
    "        print(f\"\\n-------------------------------\\nEpoch {ix+1}\")\n",
    "        train_metrics_epoch = train_loop(train_dataloader, model, loss_module, optimizer)\n",
    "        train_metrics.extend(train_metrics_epoch)\n",
    "        \n",
    "        valid_metrics_epoch = valid_loop(val_dataloader, model, loss_module)\n",
    "        valid_metrics.append((len(train_metrics), valid_metrics_epoch))\n",
    "\n",
    "        # check validation score, if improved then save model\n",
    "        if min_valid_metric > valid_metrics_epoch:\n",
    "            print(f'Validation RMSE Decreased({min_valid_metric:.6f}--->{valid_metrics_epoch:.6f}) \\t Saving The Model')\n",
    "            min_valid_metric = valid_metrics_epoch\n",
    "\n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "    print(\"Done!\")\n",
    "    train_metrics_zipped = list(zip(np.arange(0, len(train_metrics)), train_metrics))\n",
    "    \n",
    "    return {'training': train_metrics_zipped, 'validation': valid_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2dc878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(transformations, config):\n",
    "\n",
    "    dataset = dl.SentinelDataset(tile_file=config.TILE_FILE, \n",
    "                             dir_tiles=config.DIR_TILES, \n",
    "                             dir_target=config.DIR_TARGET,\n",
    "                             max_chips=config.MAX_CHIPS,\n",
    "                             transform=transforms,\n",
    "                             device=loader_device,\n",
    "                            )\n",
    "    \n",
    "    train_frac = config.TRAIN_FRAC\n",
    "    upper = int(len(dataset)*train_frac)\n",
    "    lower = len(dataset) - upper\n",
    "    train_dataset, val_dataset = random_split(dataset, [upper, lower])\n",
    "    print(f'N training samples: {len(train_dataset)}')\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "                            train_dataset,\n",
    "                            batch_size=config.BATCH_SIZE,\n",
    "                            shuffle=True,\n",
    "                            num_workers=config.WORKERS,\n",
    "                            pin_memory=True\n",
    "                            )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "                            val_dataset,\n",
    "                            batch_size=config.BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            num_workers=config.WORKERS,\n",
    "                            pin_memory=True\n",
    "                            )\n",
    "\n",
    "    in_channels = train_dataset[0]['image'].shape[0]\n",
    "    print(f'# input channels: {in_channels}')\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet50\",\n",
    "        encoder_weights=None, # 'imagenet' weights don't seem to help so start clean \n",
    "        in_channels=in_channels,                 \n",
    "        classes=1,                     \n",
    "    ).to(device)\n",
    "    #  model.load_state_dict(torch.load(f'trained_models/resnet50-sentinel2.pt'))\n",
    "\n",
    "    loss_module = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.LR)\n",
    "\n",
    "    dataset_test = dl.SentinelDataset(\n",
    "                                    tile_file=config.TILE_FILE_TEST, # specifies best months of test data \n",
    "                                    dir_tiles=config.DIR_TEST,       # test data dir\n",
    "                                    dir_target=None,          # No AGBM targets for test data \n",
    "                                    max_chips=config.MAX_CHIPS,      \n",
    "                                    transform=transforms,     # same transforms as training\n",
    "                                    device=loader_device,\n",
    "                                    )\n",
    "    \n",
    "    return model, train_dataloader, val_dataloader, loss_module, optimizer, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c241b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(metrics):\n",
    "    df_train_metrics = pd.DataFrame(metrics['training'], columns=['step', 'score'])\n",
    "    df_valid_metrics = pd.DataFrame(metrics['validation'], columns=['step', 'score'])\n",
    "    plt.plot(df_train_metrics['step'], df_train_metrics['score'], label='Training')\n",
    "    plt.plot(df_valid_metrics['step'], df_valid_metrics['score'], label='Validation')\n",
    "    plt.ylim([0, 100])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9b0d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset_test, config):\n",
    "    def save_agbm(agbm_pred, chipid):\n",
    "        im = Image.fromarray(agbm_pred)\n",
    "        save_path = os.path.join(config.DIR_PREDS, f'{chipid}_agbm.tif')\n",
    "        im.save(save_path, format='TIFF', save_all=True)\n",
    "\n",
    "    def predict_agbm(inputs, model):\n",
    "        pred = model.predict(inputs.unsqueeze(0))\n",
    "        return pred.detach().squeeze().cpu().numpy()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ix, tile in tqdm(enumerate(dataset_test), total=len(dataset_test)):\n",
    "        chipid = dataset_test.df_tile_list.iloc[ix]['chipid']\n",
    "        inputs = tile['image'].to(device)\n",
    "        agbm = predict_agbm(inputs, model)\n",
    "        save_agbm(agbm, chipid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b37cc68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(transforms, hyperparameters):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"Finland Forests\", tags=['baseline'] config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, val_loader, loss_module, optimizer, dataset_test = make(transforms, config)\n",
    "\n",
    "        # and use them to train the model\n",
    "        metrics = run_training(model, loss_module, optimizer, train_loader, val_loader, config)\n",
    "        plot_training(metrics)\n",
    "        \n",
    "        # and test its final performance\n",
    "        test(model, dataset_test)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44fbdb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(transforms, hyperparameters):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"Finland Forests\", tags=['baseline'], config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, val_loader, loss_module, optimizer, dataset_test = make(transforms, config)\n",
    "\n",
    "        # and use them to train the model\n",
    "        metrics = run_training(model, loss_module, optimizer, train_loader, val_loader, config)\n",
    "        plot_training(metrics)\n",
    "        \n",
    "        # and test its final performance\n",
    "        test(model, dataset_test)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9165def",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_pipeline(transforms, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1444afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    train_metrics = []\n",
    "    example_ct = 0\n",
    "    \n",
    "    print('Training')\n",
    "    for ix, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        X = batch['image'].to(device)\n",
    "        y = batch['label'].to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_metrics.append(np.round(np.sqrt(loss.item()), 5))\n",
    "\n",
    "        example_cnt += ix * len(batch).to('cpu')\n",
    "        if ((ix + 1) % 25) == 0:\n",
    "            train_log(train_metrics[-1], example_cnt)\n",
    "            \n",
    "    return train_metrics\n",
    "\n",
    "\n",
    "def valid_loop(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss = 0\n",
    "    valid_metrics = {}\n",
    "    \n",
    "    print('Validation')\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=num_batches):\n",
    "            X = batch['image'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "    valid_loss /= num_batches\n",
    "    valid_rmse = np.round(np.sqrt(valid_loss), 5)\n",
    "    print(f\"Validation Error: \\n RMSE: {valid_rmse:>8f} \\n\")\n",
    "    wandb.log({\"test_accuracy\": valid_rmse})\n",
    "    return valid_rmse\n",
    "\n",
    "def train_log(loss, example_ct):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"loss\": loss}, step=example_ct)\n",
    "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40cbe690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, loss_module, optimizer, train_dataloader, val_dataloader, CFG):\n",
    "    save_file = f'UNET_resnet50_20band_batch{CFG.BATCH_SIZE}_AGBMLinear_AllTrain_{CFG.EPOCHS}epoch_{datetime.now()}.pt'\n",
    "    save_path = os.path.join(CFG.SAVED_MODELS, save_file)\n",
    "    wandb.watch(model, loss_module, log=\"all\", log_freq=10)\n",
    "    min_valid_metric = np.inf\n",
    "    train_metrics = []\n",
    "    valid_metrics = []\n",
    "\n",
    "    for ix in range(CFG.EPOCHS):\n",
    "        print(f\"\\n-------------------------------\\nEpoch {ix+1}\")\n",
    "        train_metrics_epoch = train_loop(train_dataloader, model, loss_module, optimizer)\n",
    "        train_metrics.extend(train_metrics_epoch)\n",
    "        \n",
    "        valid_metrics_epoch = valid_loop(val_dataloader, model, loss_module)\n",
    "        valid_metrics.append((len(train_metrics), valid_metrics_epoch))\n",
    "\n",
    "        # check validation score, if improved then save model\n",
    "        if min_valid_metric > valid_metrics_epoch:\n",
    "            print(f'Validation RMSE Decreased({min_valid_metric:.6f}--->{valid_metrics_epoch:.6f}) \\t Saving The Model')\n",
    "            min_valid_metric = valid_metrics_epoch\n",
    "\n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "    print(\"Done!\")\n",
    "    train_metrics_zipped = list(zip(np.arange(0, len(train_metrics)), train_metrics))\n",
    "    \n",
    "    return {'training': train_metrics_zipped, 'validation': valid_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f67cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(transformations, config):\n",
    "\n",
    "    dataset = dl.SentinelDataset(tile_file=config.TILE_FILE, \n",
    "                             dir_tiles=config.DIR_TILES, \n",
    "                             dir_target=config.DIR_TARGET,\n",
    "                             max_chips=config.MAX_CHIPS,\n",
    "                             transform=transforms,\n",
    "                             device=loader_device,\n",
    "                            )\n",
    "    \n",
    "    train_frac = config.TRAIN_FRAC\n",
    "    upper = int(len(dataset)*train_frac)\n",
    "    lower = len(dataset) - upper\n",
    "    train_dataset, val_dataset = random_split(dataset, [upper, lower])\n",
    "    print(f'N training samples: {len(train_dataset)}')\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "                            train_dataset,\n",
    "                            batch_size=config.BATCH_SIZE,\n",
    "                            shuffle=True,\n",
    "                            num_workers=config.WORKERS,\n",
    "                            pin_memory=True\n",
    "                            )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "                            val_dataset,\n",
    "                            batch_size=config.BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            num_workers=config.WORKERS,\n",
    "                            pin_memory=True\n",
    "                            )\n",
    "\n",
    "    in_channels = train_dataset[0]['image'].shape[0]\n",
    "    print(f'# input channels: {in_channels}')\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet50\",\n",
    "        encoder_weights=None, # 'imagenet' weights don't seem to help so start clean \n",
    "        in_channels=in_channels,                 \n",
    "        classes=1,                     \n",
    "    ).to(device)\n",
    "    #  model.load_state_dict(torch.load(f'trained_models/resnet50-sentinel2.pt'))\n",
    "\n",
    "    loss_module = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.LR)\n",
    "\n",
    "    dataset_test = dl.SentinelDataset(\n",
    "                                    tile_file=config.TILE_FILE_TEST, # specifies best months of test data \n",
    "                                    dir_tiles=config.DIR_TEST,       # test data dir\n",
    "                                    dir_target=None,          # No AGBM targets for test data \n",
    "                                    max_chips=config.MAX_CHIPS,      \n",
    "                                    transform=transforms,     # same transforms as training\n",
    "                                    device=loader_device,\n",
    "                                    )\n",
    "    \n",
    "    return model, train_dataloader, val_dataloader, loss_module, optimizer, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f237bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(metrics):\n",
    "    df_train_metrics = pd.DataFrame(metrics['training'], columns=['step', 'score'])\n",
    "    df_valid_metrics = pd.DataFrame(metrics['validation'], columns=['step', 'score'])\n",
    "    plt.plot(df_train_metrics['step'], df_train_metrics['score'], label='Training')\n",
    "    plt.plot(df_valid_metrics['step'], df_valid_metrics['score'], label='Validation')\n",
    "    plt.ylim([0, 100])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11d61626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset_test, config):\n",
    "    def save_agbm(agbm_pred, chipid):\n",
    "        im = Image.fromarray(agbm_pred)\n",
    "        save_path = os.path.join(config.DIR_PREDS, f'{chipid}_agbm.tif')\n",
    "        im.save(save_path, format='TIFF', save_all=True)\n",
    "\n",
    "    def predict_agbm(inputs, model):\n",
    "        pred = model.predict(inputs.unsqueeze(0))\n",
    "        return pred.detach().squeeze().cpu().numpy()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ix, tile in tqdm(enumerate(dataset_test), total=len(dataset_test)):\n",
    "        chipid = dataset_test.df_tile_list.iloc[ix]['chipid']\n",
    "        inputs = tile['image'].to(device)\n",
    "        agbm = predict_agbm(inputs, model)\n",
    "        save_agbm(agbm, chipid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "037b0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(transforms, hyperparameters):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"Finland Forests\", tags=['baseline'], config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, val_loader, loss_module, optimizer, dataset_test = make(transforms, config)\n",
    "\n",
    "        # and use them to train the model\n",
    "        metrics = run_training(model, loss_module, optimizer, train_loader, val_loader, config)\n",
    "        plot_training(metrics)\n",
    "        \n",
    "        # and test its final performance\n",
    "        test(model, dataset_test)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b345b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_pipeline(transforms, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d63513b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    train_metrics = []\n",
    "    \n",
    "    print('Training')\n",
    "    for ix, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        X = batch['image'].to(device)\n",
    "        y = batch['label'].to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_metrics.append(np.round(np.sqrt(loss.item()), 5))\n",
    "\n",
    "        example_cnt = ix * len(batch)\n",
    "        if ((ix + 1) % 25) == 0:\n",
    "            train_log(train_metrics[-1], example_cnt)\n",
    "            \n",
    "    return train_metrics\n",
    "\n",
    "\n",
    "def valid_loop(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss = 0\n",
    "    valid_metrics = {}\n",
    "    \n",
    "    print('Validation')\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=num_batches):\n",
    "            X = batch['image'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "    valid_loss /= num_batches\n",
    "    valid_rmse = np.round(np.sqrt(valid_loss), 5)\n",
    "    print(f\"Validation Error: \\n RMSE: {valid_rmse:>8f} \\n\")\n",
    "    wandb.log({\"test_accuracy\": valid_rmse})\n",
    "    return valid_rmse\n",
    "\n",
    "def train_log(loss, example_ct):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"loss\": loss}, step=example_ct)\n",
    "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4b52478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, loss_module, optimizer, train_dataloader, val_dataloader, CFG):\n",
    "    save_file = f'UNET_resnet50_20band_batch{CFG.BATCH_SIZE}_AGBMLinear_AllTrain_{CFG.EPOCHS}epoch_{datetime.now()}.pt'\n",
    "    save_path = os.path.join(CFG.SAVED_MODELS, save_file)\n",
    "    wandb.watch(model, loss_module, log=\"all\", log_freq=10)\n",
    "    min_valid_metric = np.inf\n",
    "    train_metrics = []\n",
    "    valid_metrics = []\n",
    "\n",
    "    for ix in range(CFG.EPOCHS):\n",
    "        print(f\"\\n-------------------------------\\nEpoch {ix+1}\")\n",
    "        train_metrics_epoch = train_loop(train_dataloader, model, loss_module, optimizer)\n",
    "        train_metrics.extend(train_metrics_epoch)\n",
    "        \n",
    "        valid_metrics_epoch = valid_loop(val_dataloader, model, loss_module)\n",
    "        valid_metrics.append((len(train_metrics), valid_metrics_epoch))\n",
    "\n",
    "        # check validation score, if improved then save model\n",
    "        if min_valid_metric > valid_metrics_epoch:\n",
    "            print(f'Validation RMSE Decreased({min_valid_metric:.6f}--->{valid_metrics_epoch:.6f}) \\t Saving The Model')\n",
    "            min_valid_metric = valid_metrics_epoch\n",
    "\n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "    print(\"Done!\")\n",
    "    train_metrics_zipped = list(zip(np.arange(0, len(train_metrics)), train_metrics))\n",
    "    \n",
    "    return {'training': train_metrics_zipped, 'validation': valid_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6241be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(transformations, config):\n",
    "\n",
    "    dataset = dl.SentinelDataset(tile_file=config.TILE_FILE, \n",
    "                             dir_tiles=config.DIR_TILES, \n",
    "                             dir_target=config.DIR_TARGET,\n",
    "                             max_chips=config.MAX_CHIPS,\n",
    "                             transform=transforms,\n",
    "                             device=loader_device,\n",
    "                            )\n",
    "    \n",
    "    train_frac = config.TRAIN_FRAC\n",
    "    upper = int(len(dataset)*train_frac)\n",
    "    lower = len(dataset) - upper\n",
    "    train_dataset, val_dataset = random_split(dataset, [upper, lower])\n",
    "    print(f'N training samples: {len(train_dataset)}')\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "                            train_dataset,\n",
    "                            batch_size=config.BATCH_SIZE,\n",
    "                            shuffle=True,\n",
    "                            num_workers=config.WORKERS,\n",
    "                            pin_memory=True\n",
    "                            )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "                            val_dataset,\n",
    "                            batch_size=config.BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            num_workers=config.WORKERS,\n",
    "                            pin_memory=True\n",
    "                            )\n",
    "\n",
    "    in_channels = train_dataset[0]['image'].shape[0]\n",
    "    print(f'# input channels: {in_channels}')\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet50\",\n",
    "        encoder_weights=None, # 'imagenet' weights don't seem to help so start clean \n",
    "        in_channels=in_channels,                 \n",
    "        classes=1,                     \n",
    "    ).to(device)\n",
    "    #  model.load_state_dict(torch.load(f'trained_models/resnet50-sentinel2.pt'))\n",
    "\n",
    "    loss_module = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.LR)\n",
    "\n",
    "    dataset_test = dl.SentinelDataset(\n",
    "                                    tile_file=config.TILE_FILE_TEST, # specifies best months of test data \n",
    "                                    dir_tiles=config.DIR_TEST,       # test data dir\n",
    "                                    dir_target=None,          # No AGBM targets for test data \n",
    "                                    max_chips=config.MAX_CHIPS,      \n",
    "                                    transform=transforms,     # same transforms as training\n",
    "                                    device=loader_device,\n",
    "                                    )\n",
    "    \n",
    "    return model, train_dataloader, val_dataloader, loss_module, optimizer, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08cd785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(metrics):\n",
    "    df_train_metrics = pd.DataFrame(metrics['training'], columns=['step', 'score'])\n",
    "    df_valid_metrics = pd.DataFrame(metrics['validation'], columns=['step', 'score'])\n",
    "    plt.plot(df_train_metrics['step'], df_train_metrics['score'], label='Training')\n",
    "    plt.plot(df_valid_metrics['step'], df_valid_metrics['score'], label='Validation')\n",
    "    plt.ylim([0, 100])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2c11770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset_test, config):\n",
    "    def save_agbm(agbm_pred, chipid):\n",
    "        im = Image.fromarray(agbm_pred)\n",
    "        save_path = os.path.join(config.DIR_PREDS, f'{chipid}_agbm.tif')\n",
    "        im.save(save_path, format='TIFF', save_all=True)\n",
    "\n",
    "    def predict_agbm(inputs, model):\n",
    "        pred = model.predict(inputs.unsqueeze(0))\n",
    "        return pred.detach().squeeze().cpu().numpy()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ix, tile in tqdm(enumerate(dataset_test), total=len(dataset_test)):\n",
    "        chipid = dataset_test.df_tile_list.iloc[ix]['chipid']\n",
    "        inputs = tile['image'].to(device)\n",
    "        agbm = predict_agbm(inputs, model)\n",
    "        save_agbm(agbm, chipid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30ea2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(transforms, hyperparameters):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"Finland Forests\", tags=['baseline'], config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, val_loader, loss_module, optimizer, dataset_test = make(transforms, config)\n",
    "\n",
    "        # and use them to train the model\n",
    "        metrics = run_training(model, loss_module, optimizer, train_loader, val_loader, config)\n",
    "        plot_training(metrics)\n",
    "        \n",
    "        # and test its final performance\n",
    "        test(model, dataset_test)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3eaf50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_pipeline(transforms, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b23516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset_test, config):\n",
    "    def save_agbm(agbm_pred, chipid):\n",
    "        im = Image.fromarray(agbm_pred)\n",
    "        save_path = os.path.join(config.DIR_PREDS, f'{chipid}_agbm.tif')\n",
    "        im.save(save_path, format='TIFF', save_all=True)\n",
    "\n",
    "    def predict_agbm(inputs, model):\n",
    "        pred = model.predict(inputs.unsqueeze(0))\n",
    "        return pred.detach().squeeze().cpu().numpy()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ix, tile in tqdm(enumerate(dataset_test), total=len(dataset_test)):\n",
    "        chipid = dataset_test.df_tile_list.iloc[ix]['chipid']\n",
    "        inputs = tile['image'].to(device)\n",
    "        agbm = predict_agbm(inputs, model)\n",
    "        save_agbm(agbm, chipid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a218ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(transforms, hyperparameters):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"Finland Forests\", tags=['baseline'], config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, val_loader, loss_module, optimizer, dataset_test = make(transforms, config)\n",
    "\n",
    "        # and use them to train the model\n",
    "        metrics = run_training(model, loss_module, optimizer, train_loader, val_loader, config)\n",
    "        plot_training(metrics)\n",
    "        \n",
    "        # and test its final performance\n",
    "        test(model, dataset_test, config)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5de221fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_pipeline(transforms, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1de5befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "os.chdir(os.environ['WORKING_DIR'])\n",
    "import src.utils.transforms as tf\n",
    "import src.utils.data_loader_v3 as dl\n",
    "from config import CFG, CFG2\n",
    "CFG = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "033d9439",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "if torch.backends.mps.is_available(): # Mac M1/M2\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "loader_device = torch.device('cpu')  # found that using cpu for data loading was faster than gpu (for my device)\n",
    "print(f'training device: {device}')\n",
    "print(f'loader_device: {loader_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48c1d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map of tensor channels *after* transforms, not accounting for bands dropped by the DropBands transform\n",
    "# Useful for choosing which bands to keep \n",
    "band_map = CFG2.BAND_MAP\n",
    "month_map = CFG2.MONTH_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "972a79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_to_keep = CFG.BANDS # via offline feature selection  \n",
    "\n",
    "transforms = nn.Sequential(\n",
    "    tf.ClampAGBM(vmin=0., vmax=500.),                # exclude AGBM outliers, 500 is good upper limit per AGBM histograms \n",
    "    indices.AppendNDVI(index_nir=6, index_red=2),    # NDVI, index 15\n",
    "    indices.AppendNormalizedDifferenceIndex(index_a=11, index_b=12), # (VV-VH)/(VV+VH), index 16\n",
    "    indices.AppendNDBI(index_swir=8, index_nir=6),   # Difference Built-up Index for development detection, index 17\n",
    "    indices.AppendNDRE(index_nir=6, index_vre1=3),   # Red Edge Vegetation Index for canopy detection, index 18\n",
    "    indices.AppendNDSI(index_green=1, index_swir=8), # Snow Index, index 19\n",
    "    indices.AppendNDWI(index_green=1, index_nir=6),  # Difference Water Index for water detection, index 20 \n",
    "    indices.AppendSWI(index_vre1=3, index_swir2=8),  # Standardized Water-Level Index for water detection, index 21\n",
    "    tf.AppendRatioAB(index_a=11, index_b=12),        # VV/VH Ascending, index 22\n",
    "    tf.AppendRatioAB(index_a=13, index_b=14),        # VV/VH Descending, index 23\n",
    "    tf.DropBands(loader_device, bands_to_keep)       # DROPS ALL BUT SPECIFIED bands_to_keep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b53219db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    train_metrics = []\n",
    "    \n",
    "    print('Training')\n",
    "    for ix, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        X = batch['image'].to(device)\n",
    "        y = batch['label'].to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_metrics.append(np.round(np.sqrt(loss.item()), 5))\n",
    "\n",
    "        example_cnt = ix * len(batch)\n",
    "        if ((ix + 1) % 25) == 0:\n",
    "            train_log(train_metrics[-1], example_cnt)\n",
    "            \n",
    "    return train_metrics\n",
    "\n",
    "\n",
    "def valid_loop(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss = 0\n",
    "    valid_metrics = {}\n",
    "    \n",
    "    print('Validation')\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=num_batches):\n",
    "            X = batch['image'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "    valid_loss /= num_batches\n",
    "    valid_rmse = np.round(np.sqrt(valid_loss), 5)\n",
    "    print(f\"Validation Error: \\n RMSE: {valid_rmse:>8f} \\n\")\n",
    "    wandb.log({\"test_accuracy\": valid_rmse})\n",
    "    return valid_rmse\n",
    "\n",
    "def train_log(loss, example_ct):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"loss\": loss}, step=example_ct)\n",
    "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6d364a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, loss_module, optimizer, train_dataloader, val_dataloader, CFG):\n",
    "    save_file = f'UNET_resnet50_20band_batch{CFG.BATCH_SIZE}_AGBMLinear_AllTrain_{CFG.EPOCHS}epoch_{datetime.now()}.pt'\n",
    "    save_path = os.path.join(CFG.SAVED_MODELS, save_file)\n",
    "    wandb.watch(model, loss_module, log=\"all\", log_freq=10)\n",
    "    min_valid_metric = np.inf\n",
    "    train_metrics = []\n",
    "    valid_metrics = []\n",
    "\n",
    "    for ix in range(CFG.EPOCHS):\n",
    "        print(f\"\\n-------------------------------\\nEpoch {ix+1}\")\n",
    "        train_metrics_epoch = train_loop(train_dataloader, model, loss_module, optimizer)\n",
    "        train_metrics.extend(train_metrics_epoch)\n",
    "        \n",
    "        valid_metrics_epoch = valid_loop(val_dataloader, model, loss_module)\n",
    "        valid_metrics.append((len(train_metrics), valid_metrics_epoch))\n",
    "\n",
    "        # check validation score, if improved then save model\n",
    "        if min_valid_metric > valid_metrics_epoch:\n",
    "            print(f'Validation RMSE Decreased({min_valid_metric:.6f}--->{valid_metrics_epoch:.6f}) \\t Saving The Model')\n",
    "            min_valid_metric = valid_metrics_epoch\n",
    "\n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "    print(\"Done!\")\n",
    "    train_metrics_zipped = list(zip(np.arange(0, len(train_metrics)), train_metrics))\n",
    "    \n",
    "    return {'training': train_metrics_zipped, 'validation': valid_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c99b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(transformations, config):\n",
    "\n",
    "    dataset = dl.SentinelDataset(tile_file=config.TILE_FILE, \n",
    "                             dir_tiles=config.DIR_TILES, \n",
    "                             dir_target=config.DIR_TARGET,\n",
    "                             max_chips=config.MAX_CHIPS,\n",
    "                             transform=transforms,\n",
    "                             device=loader_device,\n",
    "                            )\n",
    "    \n",
    "    train_frac = config.TRAIN_FRAC\n",
    "    upper = int(len(dataset)*train_frac)\n",
    "    lower = len(dataset) - upper\n",
    "    train_dataset, val_dataset = random_split(dataset, [upper, lower])\n",
    "    print(f'N training samples: {len(train_dataset)}')\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "                            train_dataset,\n",
    "                            batch_size=config.BATCH_SIZE,\n",
    "                            shuffle=True,\n",
    "                            num_workers=config.WORKERS,\n",
    "                            pin_memory=True\n",
    "                            )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "                            val_dataset,\n",
    "                            batch_size=config.BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            num_workers=config.WORKERS,\n",
    "                            pin_memory=True\n",
    "                            )\n",
    "\n",
    "    in_channels = train_dataset[0]['image'].shape[0]\n",
    "    print(f'# input channels: {in_channels}')\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet50\",\n",
    "        encoder_weights=None, # 'imagenet' weights don't seem to help so start clean \n",
    "        in_channels=in_channels,                 \n",
    "        classes=1,                     \n",
    "    ).to(device)\n",
    "    #  model.load_state_dict(torch.load(f'trained_models/resnet50-sentinel2.pt'))\n",
    "\n",
    "    loss_module = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.LR)\n",
    "\n",
    "    dataset_test = dl.SentinelDataset(\n",
    "                                    tile_file=config.TILE_FILE_TEST, # specifies best months of test data \n",
    "                                    dir_tiles=config.DIR_TEST,       # test data dir\n",
    "                                    dir_target=None,          # No AGBM targets for test data \n",
    "                                    max_chips=config.MAX_CHIPS,      \n",
    "                                    transform=transforms,     # same transforms as training\n",
    "                                    device=loader_device,\n",
    "                                    )\n",
    "    \n",
    "    return model, train_dataloader, val_dataloader, loss_module, optimizer, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d38f7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(metrics):\n",
    "    df_train_metrics = pd.DataFrame(metrics['training'], columns=['step', 'score'])\n",
    "    df_valid_metrics = pd.DataFrame(metrics['validation'], columns=['step', 'score'])\n",
    "    plt.plot(df_train_metrics['step'], df_train_metrics['score'], label='Training')\n",
    "    plt.plot(df_valid_metrics['step'], df_valid_metrics['score'], label='Validation')\n",
    "    plt.ylim([0, 100])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac0aaada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset_test, config):\n",
    "    def save_agbm(agbm_pred, chipid):\n",
    "        im = Image.fromarray(agbm_pred)\n",
    "        save_path = os.path.join(config.DIR_PREDS, f'{chipid}_agbm.tif')\n",
    "        im.save(save_path, format='TIFF', save_all=True)\n",
    "\n",
    "    def predict_agbm(inputs, model):\n",
    "        pred = model.predict(inputs.unsqueeze(0))\n",
    "        return pred.detach().squeeze().cpu().numpy()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ix, tile in tqdm(enumerate(dataset_test), total=len(dataset_test)):\n",
    "        chipid = dataset_test.df_tile_list.iloc[ix]['chipid']\n",
    "        inputs = tile['image'].to(device)\n",
    "        agbm = predict_agbm(inputs, model)\n",
    "        save_agbm(agbm, chipid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb42e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(transforms, hyperparameters):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"Finland Forests\", tags=['baseline'], config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, val_loader, loss_module, optimizer, dataset_test = make(transforms, config)\n",
    "\n",
    "        # and use them to train the model\n",
    "        metrics = run_training(model, loss_module, optimizer, train_loader, val_loader, config)\n",
    "        plot_training(metrics)\n",
    "        \n",
    "        # and test its final performance\n",
    "        test(model, dataset_test, config)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2fb8d100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/broug/Desktop/DD-Finland-Forests/wandb/run-20230122_154427-maimgbp9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/g-broughton/Finland%20Forests/runs/maimgbp9\" target=\"_blank\">devout-valley-5</a></strong> to <a href=\"https://wandb.ai/g-broughton/Finland%20Forests\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/g-broughton/Finland%20Forests\" target=\"_blank\">https://wandb.ai/g-broughton/Finland%20Forests</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/g-broughton/Finland%20Forests/runs/maimgbp9\" target=\"_blank\">https://wandb.ai/g-broughton/Finland%20Forests/runs/maimgbp9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model_pipeline(transforms, CFG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
