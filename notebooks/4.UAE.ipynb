{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import pprint\n",
    "import time\n",
    "import dotenv\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchnet as tnt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "os.chdir(os.environ['WORKING_DIR'])\n",
    "\n",
    "from src.utils import utils, model_utils\n",
    "#from src.dataset import PASTIS_Dataset\n",
    "from src.learning.metrics import confusion_matrix_analysis\n",
    "from src.learning.miou import IoU\n",
    "from src.learning.weight_init import weight_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(\n",
    "    model, data_loader, criterion, config, optimizer=None, mode=\"train\", device=None\n",
    "):\n",
    "    loss_meter = tnt.meter.AverageValueMeter()\n",
    "    iou_meter = IoU(\n",
    "        num_classes=config.num_classes,\n",
    "        ignore_index=config.ignore_index,\n",
    "        cm_device=config.device,\n",
    "    )\n",
    "\n",
    "    t_start = time.time()\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        if device is not None:\n",
    "            batch = recursive_todevice(batch, device)\n",
    "        (x, dates), y = batch\n",
    "        y = y.long()\n",
    "\n",
    "        if mode != \"train\":\n",
    "            with torch.no_grad():\n",
    "                out = model(x, batch_positions=dates)\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x, batch_positions=dates)\n",
    "\n",
    "        loss = criterion(out, y)\n",
    "        if mode == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = out.argmax(dim=1)\n",
    "        iou_meter.add(pred, y)\n",
    "        loss_meter.add(loss.item())\n",
    "\n",
    "        if (i + 1) % config.display_step == 0:\n",
    "            miou, acc = iou_meter.get_miou_acc()\n",
    "            print(\n",
    "                \"Step [{}/{}], Loss: {:.4f}, Acc : {:.2f}, mIoU {:.2f}\".format(\n",
    "                    i + 1, len(data_loader), loss_meter.value()[0], acc, miou\n",
    "                )\n",
    "            )\n",
    "\n",
    "    t_end = time.time()\n",
    "    total_time = t_end - t_start\n",
    "    print(\"Epoch time : {:.1f}s\".format(total_time))\n",
    "    miou, acc = iou_meter.get_miou_acc()\n",
    "    metrics = {\n",
    "        f\"{mode}_accuracy\": acc,\n",
    "        f\"{mode}_loss\": loss_meter.value()[0],\n",
    "        f\"{mode}_IoU\": miou,\n",
    "        f\"{mode}_epoch_time\": total_time,\n",
    "    }\n",
    "\n",
    "    return (metrics, iou_meter.conf_metric.value()) if mode == \"test\" else metrics\n",
    "\n",
    "def recursive_todevice(x, device):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.to(device)\n",
    "    elif isinstance(x, dict):\n",
    "        return {k: recursive_todevice(v, device) for k, v in x.items()}\n",
    "    else:\n",
    "        return [recursive_todevice(c, device) for c in x]\n",
    "\n",
    "def prepare_output(config):\n",
    "    os.makedirs(config.res_dir, exist_ok=True)\n",
    "    for fold in range(1, 6):\n",
    "        os.makedirs(os.path.join(config.res_dir, f\"Fold_{fold}\"), exist_ok=True)\n",
    "\n",
    "def checkpoint(fold, log, config):\n",
    "    with open(os.path.join(config.res_dir, f\"Fold_{fold}\", \"trainlog.json\"), \"w\") as outfile:\n",
    "        json.dump(log, outfile, indent=4)\n",
    "\n",
    "def save_results(fold, metrics, conf_mat, config):\n",
    "    with open(os.path.join(config.res_dir, f\"Fold_{fold}\", \"test_metrics.json\"), \"w\") as outfile:\n",
    "        json.dump(metrics, outfile, indent=4)\n",
    "    pkl.dump(\n",
    "        conf_mat,\n",
    "        open(\n",
    "            os.path.join(config.res_dir, f\"Fold_{fold}\", \"conf_mat.pkl\"), \"wb\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def overall_performance(config):\n",
    "    cm = np.zeros((config.num_classes, config.num_classes))\n",
    "    for fold in range(1, 6):\n",
    "        cm += pkl.load(\n",
    "            open(\n",
    "                os.path.join(config.res_dir, f\"Fold_{fold}\", \"conf_mat.pkl\"),\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if config.ignore_index is not None:\n",
    "        cm = np.delete(cm, config.ignore_index, axis=0)\n",
    "        cm = np.delete(cm, config.ignore_index, axis=1)\n",
    "\n",
    "    _, perf = confusion_matrix_analysis(cm)\n",
    "\n",
    "    print(\"Overall performance:\")\n",
    "    print(f'Acc: {perf[\"Accuracy\"]},  IoU: {perf[\"MACRO_IoU\"]}')\n",
    "\n",
    "    with open(os.path.join(config.res_dir, \"overall.json\"), \"w\") as file:\n",
    "        file.write(json.dumps(perf, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    fold_sequence = [\n",
    "        [[1, 2, 3], [4], [5]],\n",
    "        [[2, 3, 4], [5], [1]],\n",
    "        [[3, 4, 5], [1], [2]],\n",
    "        [[4, 5, 1], [2], [3]],\n",
    "        [[5, 1, 2], [3], [4]],\n",
    "    ]\n",
    "\n",
    "    np.random.seed(config.rdm_seed)\n",
    "    torch.manual_seed(config.rdm_seed)\n",
    "    prepare_output(config)\n",
    "    device = torch.device(config.device)\n",
    "\n",
    "    fold_sequence = (\n",
    "        fold_sequence if config.fold is None else [fold_sequence[config.fold - 1]]\n",
    "    )\n",
    "    for fold, (train_folds, val_fold, test_fold) in enumerate(fold_sequence):\n",
    "        if config.fold is not None:\n",
    "            fold = config.fold - 1\n",
    "\n",
    "        # Dataset definition\n",
    "        dt_args = dict(\n",
    "            folder=config.dataset_folder,\n",
    "            norm=True,\n",
    "            reference_date=config.ref_date,\n",
    "            mono_date=config.mono_date,\n",
    "            target=\"semantic\",\n",
    "            sats=[\"S2\"],\n",
    "        )\n",
    "\n",
    "        dt_train = PASTIS_Dataset(**dt_args, folds=train_folds, cache=config.cache)\n",
    "        dt_val = PASTIS_Dataset(**dt_args, folds=val_fold, cache=config.cache)\n",
    "        dt_test = PASTIS_Dataset(**dt_args, folds=test_fold)\n",
    "\n",
    "        collate_fn = lambda x: utils.pad_collate(x, pad_value=config.pad_value)\n",
    "        train_loader = data.DataLoader(\n",
    "            dt_train,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            collate_fn=collate_fn,\n",
    "        )\n",
    "        val_loader = data.DataLoader(\n",
    "            dt_val,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            collate_fn=collate_fn,\n",
    "        )\n",
    "        test_loader = data.DataLoader(\n",
    "            dt_test,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            collate_fn=collate_fn,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"Train {}, Val {}, Test {}\".format(len(dt_train), len(dt_val), len(dt_test))\n",
    "        )\n",
    "\n",
    "        # Model definition\n",
    "        model = model_utils.get_model(config, mode=\"semantic\")\n",
    "        config.N_params = utils.get_ntrainparams(model)\n",
    "        with open(os.path.join(config.res_dir, \"conf.json\"), \"w\") as file:\n",
    "            file.write(json.dumps(vars(config), indent=4))\n",
    "        print(model)\n",
    "        print(\"TOTAL TRAINABLE PARAMETERS :\", config.N_params)\n",
    "        print(\"Trainable layers:\")\n",
    "        for name, p in model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                print(name)\n",
    "        model = model.to(device)\n",
    "        model.apply(weight_init)\n",
    "\n",
    "        # Optimizer and Loss\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "        weights = torch.ones(config.num_classes, device=device).float()\n",
    "        weights[config.ignore_index] = 0\n",
    "        criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "        # Training loop\n",
    "        trainlog = {}\n",
    "        best_mIoU = 0\n",
    "        for epoch in range(1, config.epochs + 1):\n",
    "            print(\"EPOCH {}/{}\".format(epoch, config.epochs))\n",
    "\n",
    "            model.train()\n",
    "            train_metrics = iterate(\n",
    "                model,\n",
    "                data_loader=train_loader,\n",
    "                criterion=criterion,\n",
    "                config=config,\n",
    "                optimizer=optimizer,\n",
    "                mode=\"train\",\n",
    "                device=device,\n",
    "            )\n",
    "            if epoch % config.val_every == 0 and epoch > config.val_after:\n",
    "                print(\"Validation . . . \")\n",
    "                model.eval()\n",
    "                val_metrics = iterate(\n",
    "                    model,\n",
    "                    data_loader=val_loader,\n",
    "                    criterion=criterion,\n",
    "                    config=config,\n",
    "                    optimizer=optimizer,\n",
    "                    mode=\"val\",\n",
    "                    device=device,\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                    \"Loss {:.4f},  Acc {:.2f},  IoU {:.4f}\".format(\n",
    "                        val_metrics[\"val_loss\"],\n",
    "                        val_metrics[\"val_accuracy\"],\n",
    "                        val_metrics[\"val_IoU\"],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                trainlog[epoch] = {**train_metrics, **val_metrics}\n",
    "                checkpoint(fold + 1, trainlog, config)\n",
    "                if val_metrics[\"val_IoU\"] >= best_mIoU:\n",
    "                    best_mIoU = val_metrics[\"val_IoU\"]\n",
    "                    torch.save(\n",
    "                        {\n",
    "                            \"epoch\": epoch,\n",
    "                            \"state_dict\": model.state_dict(),\n",
    "                            \"optimizer\": optimizer.state_dict(),\n",
    "                        },\n",
    "                        os.path.join(\n",
    "                            config.res_dir, \"Fold_{}\".format(fold + 1), \"model.pth.tar\"\n",
    "                        ),\n",
    "                    )\n",
    "            else:\n",
    "                trainlog[epoch] = {**train_metrics}\n",
    "                checkpoint(fold + 1, trainlog, config)\n",
    "\n",
    "        print(\"Testing best epoch . . .\")\n",
    "        model.load_state_dict(\n",
    "            torch.load(\n",
    "                os.path.join(\n",
    "                    config.res_dir, \"Fold_{}\".format(fold + 1), \"model.pth.tar\"\n",
    "                )\n",
    "            )[\"state_dict\"]\n",
    "        )\n",
    "        model.eval()\n",
    "\n",
    "        test_metrics, conf_mat = iterate(\n",
    "            model,\n",
    "            data_loader=test_loader,\n",
    "            criterion=criterion,\n",
    "            config=config,\n",
    "            optimizer=optimizer,\n",
    "            mode=\"test\",\n",
    "            device=device,\n",
    "        )\n",
    "        print(\n",
    "            \"Loss {:.4f},  Acc {:.2f},  IoU {:.4f}\".format(\n",
    "                test_metrics[\"test_loss\"],\n",
    "                test_metrics[\"test_accuracy\"],\n",
    "                test_metrics[\"test_IoU\"],\n",
    "            )\n",
    "        )\n",
    "        save_results(fold + 1, test_metrics, conf_mat.cpu().numpy(), config)\n",
    "\n",
    "    if config.fold is None:\n",
    "        overall_performance(config)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = parser.parse_args()\n",
    "    for k, v in vars(config).items():\n",
    "        if k in list_args and v is not None:\n",
    "            v = v.replace(\"[\", \"\")\n",
    "            v = v.replace(\"]\", \"\")\n",
    "            config.__setattr__(k, list(map(int, v.split(\",\"))))\n",
    "\n",
    "    assert config.num_classes == config.out_conv[-1]\n",
    "\n",
    "    pprint.pprint(config)\n",
    "    main(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bff0657a98b8ee576cbe89028f6a544b770fee234379978e147d89ef60d92ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
